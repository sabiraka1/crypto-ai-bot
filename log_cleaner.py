import pandas as pd
import os
from datetime import datetime, timedelta
import logging

SIGNAL_CSV = "sinyal_fiyat_analizi.csv"
CLOSED_CSV = "closed_trades.csv"
ERROR_CSV = "error_signals.csv"
CHARTS_DIR = "charts"
MODELS_DIR = "models"

logger = logging.getLogger(__name__)

def clean_csv(file_path, date_column, days=60):
    """–û—á–∏—Å—Ç–∫–∞ CSV —Ñ–∞–π–ª–∞ –æ—Ç —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π"""
    if not os.path.exists(file_path):
        logger.info(f"üìÅ –§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return

    try:
        df = pd.read_csv(file_path)
        
        if date_column not in df.columns:
            logger.warning(f"‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ {date_column} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ {file_path}")
            return
            
        original_count = len(df)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ datetime
        df[date_column] = pd.to_datetime(df[date_column], errors='coerce')
        
        # –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å–∏ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –¥–∞—Ç–∞–º–∏
        df = df.dropna(subset=[date_column])
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
        cutoff = datetime.now() - timedelta(days=days)
        df_filtered = df[df[date_column] >= cutoff]
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ
        df_filtered.to_csv(file_path, index=False)
        
        removed_count = original_count - len(df_filtered)
        logger.info(f"üßπ {file_path}: —É–¥–∞–ª–µ–Ω–æ {removed_count} –∑–∞–ø–∏—Å–µ–π, –æ—Å—Ç–∞–ª–æ—Å—å {len(df_filtered)}")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ {file_path}: {e}")

def clean_charts(days=3):
    """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤"""
    if not os.path.exists(CHARTS_DIR):
        logger.info(f"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {CHARTS_DIR} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return

    try:
        cutoff = datetime.now() - timedelta(days=days)
        removed_count = 0
        
        for filename in os.listdir(CHARTS_DIR):
            file_path = os.path.join(CHARTS_DIR, filename)
            
            if filename.endswith(('.png', '.jpg', '.jpeg')):
                try:
                    file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                    
                    if file_mtime < cutoff:
                        os.remove(file_path)
                        removed_count += 1
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {filename}: {e}")
        
        logger.info(f"üßπ –£–¥–∞–ª–µ–Ω–æ {removed_count} —Å—Ç–∞—Ä—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤: {e}")

def clean_old_models(keep_count=3):
    """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π, –æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N"""
    if not os.path.exists(MODELS_DIR):
        logger.info(f"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {MODELS_DIR} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return

    try:
        model_files = []
        
        for filename in os.listdir(MODELS_DIR):
            if filename.endswith('.pkl'):
                file_path = os.path.join(MODELS_DIR, filename)
                file_mtime = os.path.getmtime(file_path)
                model_files.append((file_path, file_mtime, filename))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
        model_files.sort(key=lambda x: x[1], reverse=True)
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –º–æ–¥–µ–ª–∏
        removed_count = 0
        for file_path, _, filename in model_files[keep_count:]:
            if 'backup' not in filename.lower():  # –ù–µ —É–¥–∞–ª—è–µ–º backup —Ñ–∞–π–ª—ã
                try:
                    os.remove(file_path)
                    removed_count += 1
                    logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏: {filename}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {filename}: {e}")
        
        logger.info(f"üßπ –£–¥–∞–ª–µ–Ω–æ {removed_count} —Å—Ç–∞—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")

def clean_logs():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—á–∏—Å—Ç–∫–∏ –≤—Å–µ—Ö –ª–æ–≥–æ–≤"""
    logger.info("üßπ –ù–∞—á–∏–Ω–∞—é –æ—á–∏—Å—Ç–∫—É –ª–æ–≥–æ–≤ –∏ —Ñ–∞–π–ª–æ–≤...")
    
    # –û—á–∏—Å—Ç–∫–∞ CSV —Ñ–∞–π–ª–æ–≤
    clean_csv(SIGNAL_CSV, "datetime", days=90)  # –°–∏–≥–Ω–∞–ª—ã –∑–∞ 3 –º–µ—Å—è—Ü–∞
    clean_csv(CLOSED_CSV, "close_datetime", days=365)  # –°–¥–µ–ª–∫–∏ –∑–∞ –≥–æ–¥
    clean_csv(ERROR_CSV, "timestamp", days=60)  # –û—à–∏–±–∫–∏ –∑–∞ 2 –º–µ—Å—è—Ü–∞
    
    # –û—á–∏—Å—Ç–∫–∞ –≥—Ä–∞—Ñ–∏–∫–æ–≤
    clean_charts(days=7)  # –ì—Ä–∞—Ñ–∏–∫–∏ –∑–∞ –Ω–µ–¥–µ–ª—é
    
    # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π
    clean_old_models(keep_count=5)  # –û—Å—Ç–∞–≤–ª—è–µ–º 5 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π
    
    logger.info("‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

def get_disk_usage():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –¥–∏—Å–∫–∞"""
    try:
        usage_info = {}
        
        # –†–∞–∑–º–µ—Ä—ã CSV —Ñ–∞–π–ª–æ–≤
        for file_path in [SIGNAL_CSV, CLOSED_CSV, ERROR_CSV]:
            if os.path.exists(file_path):
                size_mb = os.path.getsize(file_path) / (1024 * 1024)
                usage_info[file_path] = f"{size_mb:.1f} MB"
        
        # –†–∞–∑–º–µ—Ä –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏
        if os.path.exists(CHARTS_DIR):
            total_size = sum(
                os.path.getsize(os.path.join(CHARTS_DIR, f))
                for f in os.listdir(CHARTS_DIR)
                if os.path.isfile(os.path.join(CHARTS_DIR, f))
            )
            usage_info[CHARTS_DIR] = f"{total_size / (1024 * 1024):.1f} MB"
        
        # –†–∞–∑–º–µ—Ä –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –º–æ–¥–µ–ª—è–º–∏
        if os.path.exists(MODELS_DIR):
            total_size = sum(
                os.path.getsize(os.path.join(MODELS_DIR, f))
                for f in os.listdir(MODELS_DIR)
                if os.path.isfile(os.path.join(MODELS_DIR, f))
            )
            usage_info[MODELS_DIR] = f"{total_size / (1024 * 1024):.1f} MB"
        
        return usage_info
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∏—Å–∫–µ: {e}")
        return {}

def cleanup_emergency():
    """–≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –Ω–µ—Ö–≤–∞—Ç–∫–µ –º–µ—Å—Ç–∞"""
    logger.warning("üö® –ó–∞–ø—É—Å–∫ —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏!")
    
    # –ë–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
    clean_csv(SIGNAL_CSV, "datetime", days=30)  # –¢–æ–ª—å–∫–æ –º–µ—Å—è—Ü —Å–∏–≥–Ω–∞–ª–æ–≤
    clean_csv(ERROR_CSV, "timestamp", days=14)  # –¢–æ–ª—å–∫–æ 2 –Ω–µ–¥–µ–ª–∏ –æ—à–∏–±–æ–∫
    
    # –£–¥–∞–ª—è–µ–º –≤—Å–µ –≥—Ä–∞—Ñ–∏–∫–∏ —Å—Ç–∞—Ä—à–µ —Å—É—Ç–æ–∫
    clean_charts(days=1)
    
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ 2 –ø–æ—Å–ª–µ–¥–Ω–∏–µ –º–æ–¥–µ–ª–∏
    clean_old_models(keep_count=2)
    
    logger.info("‚úÖ –≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

def schedule_cleanup():
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ - –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏"""
    try:
        logger.info("‚è∞ –ó–∞–ø—É—Å–∫ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏")
        clean_logs()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        usage = get_disk_usage()
        logger.info("üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∏—Å–∫–∞ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏:")
        for path, size in usage.items():
            logger.info(f"  {path}: {size}")
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ—á–∏—Å—Ç–∫–µ: {e}")

if __name__ == "__main__":
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è standalone –∑–∞–ø—É—Å–∫–∞
    logging.basicConfig(level=logging.INFO)
    clean_logs()
