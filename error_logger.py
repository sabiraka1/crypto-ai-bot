import pandas as pd
import os
from datetime import datetime

ERROR_FILE = "error_signals.csv"

def log_error_signal(row):
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ—á–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
    try:
        # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –∑–∞–ø–∏—Å—å –æ–± –æ—à–∏–±–∫–µ
        error_data = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "signal": row.get("signal", "UNKNOWN"),
            "price": row.get("price", 0),
            "rsi": row.get("rsi", 0),
            "macd": row.get("macd", 0),
            "score": row.get("score", 0),
            "confidence": row.get("confidence", 0),
            "pattern": row.get("pattern", "NONE"),
            "pattern_score": row.get("pattern_score", 0),
            "pattern_direction": row.get("pattern_direction", "NEUTRAL"),
            "pnl_percent": row.get("pnl_percent", 0),
            "reason": row.get("reason", "UNKNOWN"),
            "explanation": explain_error(row)
        }
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
        df = pd.DataFrame([error_data])
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
        if os.path.exists(ERROR_FILE):
            df.to_csv(ERROR_FILE, mode='a', index=False, header=False)
        else:
            df.to_csv(ERROR_FILE, index=False, header=True)
            
        print(f"‚úÖ –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∞–Ω–∞ –≤ {ERROR_FILE}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ error log: {e}")

def explain_error(row):
    """–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–∏—á–∏–Ω—ã –æ—à–∏–±–∫–∏ —Å–∏–≥–Ω–∞–ª–∞"""
    signal = row.get("signal", "")
    rsi = row.get("rsi", 0)
    macd = row.get("macd", 0)
    score = row.get("score", 0)
    confidence = row.get("confidence", 0)
    pattern_direction = row.get("pattern_direction", "")
    pattern_score = row.get("pattern_score", 0)
    pnl_percent = row.get("pnl_percent", 0)
    
    reasons = []
    
    # –ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
    if score < 0.5:
        reasons.append(f"–ù–∏–∑–∫–∏–π AI score ({score:.3f})")
    
    if confidence < 50:
        reasons.append(f"–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ({confidence:.1f}%)")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø—É —Å–∏–≥–Ω–∞–ª–∞
    if "BUY" in signal:
        if rsi > 70:
            reasons.append(f"RSI –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω ({rsi:.1f})")
        if macd < -100:
            reasons.append(f"MACD —Å–∏–ª—å–Ω–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π ({macd:.4f})")
        if pattern_direction == "BEARISH":
            reasons.append("–ú–µ–¥–≤–µ–∂–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—Ç BUY")
        if pattern_score < 3 and row.get("pattern", "") != "NONE":
            reasons.append(f"–°–ª–∞–±—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω ({pattern_score:.1f})")
            
    elif "SELL" in signal:
        if rsi < 30:
            reasons.append(f"RSI –ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω ({rsi:.1f})")
        if macd > 100:
            reasons.append(f"MACD —Å–∏–ª—å–Ω–æ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π ({macd:.4f})")
        if pattern_direction == "BULLISH":
            reasons.append("–ë—ã—á–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—Ç SELL")
        if pattern_score < 3 and row.get("pattern", "") != "NONE":
            reasons.append(f"–°–ª–∞–±—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω ({pattern_score:.1f})")
    
    # –ê–Ω–∞–ª–∏–∑ —É–±—ã—Ç–∫–∞
    if pnl_percent < -0.05:  # –ë–æ–ª—å—à–µ 5% —É–±—ã—Ç–∫–∞
        reasons.append("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —É–±—ã—Ç–æ–∫")
    elif pnl_percent < -0.02:  # –ë–æ–ª—å—à–µ 2% —É–±—ã—Ç–∫–∞
        reasons.append("–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π —É–±—ã—Ç–æ–∫")
    
    if not reasons:
        reasons.append("–ù–µ–±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω—ã–µ —Ä—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è")
    
    return "; ".join(reasons)

def get_error_statistics():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –æ—à–∏–±–∫–∞–º"""
    if not os.path.exists(ERROR_FILE):
        return None
    
    try:
        df = pd.read_csv(ERROR_FILE)
        
        if len(df) == 0:
            return None
        
        stats = {
            "total_errors": len(df),
            "avg_loss": df["pnl_percent"].mean() * 100,
            "max_loss": df["pnl_percent"].min() * 100,
            "avg_rsi": df["rsi"].mean(),
            "avg_macd": df["macd"].mean(),
            "avg_score": df["score"].mean(),
            "avg_confidence": df["confidence"].mean(),
            "signal_distribution": df["signal"].value_counts().to_dict(),
            "common_reasons": get_common_error_reasons(df)
        }
        
        return stats
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ—à–∏–±–æ–∫: {e}")
        return None

def get_common_error_reasons(df):
    """–ê–Ω–∞–ª–∏–∑ –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã—Ö –ø—Ä–∏—á–∏–Ω –æ—à–∏–±–æ–∫"""
    if "explanation" not in df.columns:
        return {}
    
    try:
        # –†–∞–∑–±–∏–≤–∞–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã
        all_reasons = []
        for explanation in df["explanation"].dropna():
            reasons = explanation.split("; ")
            all_reasons.extend(reasons)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É
        from collections import Counter
        reason_counts = Counter(all_reasons)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-5 –ø—Ä–∏—á–∏–Ω
        return dict(reason_counts.most_common(5))
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏—á–∏–Ω: {e}")
        return {}

def clean_old_errors(days=30):
    """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π –æ–± –æ—à–∏–±–∫–∞—Ö"""
    if not os.path.exists(ERROR_FILE):
        return
    
    try:
        df = pd.read_csv(ERROR_FILE)
        
        if "timestamp" not in df.columns:
            return
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º timestamp –≤ datetime
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–ø–∏—Å–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π
        cutoff_date = datetime.now() - pd.Timedelta(days=days)
        df_filtered = df[df['timestamp'] >= cutoff_date]
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        df_filtered.to_csv(ERROR_FILE, index=False)
        
        removed_count = len(df) - len(df_filtered)
        print(f"üßπ –û—á–∏—â–µ–Ω–æ {removed_count} —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π –æ–± –æ—à–∏–±–∫–∞—Ö")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ error log: {e}")

def generate_error_report():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –ø–æ –æ—à–∏–±–∫–∞–º"""
    stats = get_error_statistics()
    
    if not stats:
        return "üìä –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ–± –æ—à–∏–±–∫–∞—Ö"
    
    report = f"""
üìä –û–¢–ß–ï–¢ –ü–û –û–®–ò–ë–ö–ê–ú

üìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:
‚Ä¢ –í—Å–µ–≥–æ –æ—à–∏–±–æ–∫: {stats['total_errors']}
‚Ä¢ –°—Ä–µ–¥–Ω–∏–π —É–±—ã—Ç–æ–∫: {stats['avg_loss']:.2f}%
‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É–±—ã—Ç–æ–∫: {stats['max_loss']:.2f}%

ü§ñ AI –ú–µ—Ç—Ä–∏–∫–∏:
‚Ä¢ –°—Ä–µ–¥–Ω–∏–π AI Score: {stats['avg_score']:.3f}
‚Ä¢ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {stats['avg_confidence']:.1f}%

üìä –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏:
‚Ä¢ –°—Ä–µ–¥–Ω–∏–π RSI: {stats['avg_rsi']:.1f}
‚Ä¢ –°—Ä–µ–¥–Ω–∏–π MACD: {stats['avg_macd']:.4f}

üéØ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤:"""
    
    for signal, count in stats['signal_distribution'].items():
        report += f"\n‚Ä¢ {signal}: {count}"
    
    report += "\n\nüîç –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã –æ—à–∏–±–æ–∫:"
    for reason, count in stats['common_reasons'].items():
        report += f"\n‚Ä¢ {reason}: {count}"
    
    return report
