import pandas as pd
import numpy as np
import joblib
import os
import logging
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt

MODEL_PATH = "models/ai_model.pkl"
OLD_MODEL_PATH = "models/ai_model_backup.pkl"
CSV_FILE = "sinyal_fiyat_analizi.csv"

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_data():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    if not os.path.exists(CSV_FILE):
        logger.warning(f"‚ö†Ô∏è –§–∞–π–ª {CSV_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return None, None, None
    
    try:
        df = pd.read_csv(CSV_FILE)
        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_cols = ["signal", "rsi", "macd", "success"]
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            logger.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_cols}")
            return None, None, None
        
        # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df = df.dropna(subset=required_cols)
        
        if len(df) < 10:
            logger.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(df)} –∑–∞–ø–∏—Å–µ–π")
            return None, None, None
        
        # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        df["signal_encoded"] = df["signal"].map({
            "BUY": 1, "STRONG_BUY": 1.5, 
            "SELL": -1, "STRONG_SELL": -1.5, 
            "HOLD": 0, "NONE": 0, "ERROR": 0
        }).fillna(0)
        
        df["result_encoded"] = df["success"].astype(int)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        feature_cols = ["rsi", "macd", "signal_encoded"]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –µ—Å–ª–∏ –æ–Ω–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        optional_features = [
            "pattern_score", "confidence", "buy_score", "sell_score"
        ]
        
        for feat in optional_features:
            if feat in df.columns:
                df[feat] = pd.to_numeric(df[feat], errors='coerce').fillna(0)
                feature_cols.append(feat)
        
        # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –µ—Å–ª–∏ –µ—Å—Ç—å
        if "pattern_direction" in df.columns:
            df["pattern_direction_encoded"] = df["pattern_direction"].map({
                "BULLISH": 1, "BEARISH": -1, "REVERSAL": 0.5, 
                "INDECISION": 0, "NEUTRAL": 0
            }).fillna(0)
            feature_cols.append("pattern_direction_encoded")
        
        X = df[feature_cols]
        y = df["result_encoded"]
        
        logger.info(f"üìà –ü—Ä–∏–∑–Ω–∞–∫–∏: {feature_cols}")
        logger.info(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {y.value_counts().to_dict()}")
        
        return X, y, feature_cols
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return None, None, None

def train_model():
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    logger.info("üß† –ù–∞—á–∏–Ω–∞—é –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    
    X, y, feature_names = load_data()
    
    if X is None or len(X) < 20:
        logger.warning("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏!")
        
        # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–∞–ª–æ
        if not os.path.exists(MODEL_PATH):
            create_basic_model()
        return
    
    try:
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # –û–±—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        new_model = RandomForestClassifier(
            n_estimators=200,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42
        )
        
        new_model.fit(X_train, y_train)
        
        # –û—Ü–µ–Ω–∫–∞ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        y_pred = new_model.predict(X_test)
        new_acc = accuracy_score(y_test, y_pred)
        logger.info(f"üìà –¢–æ—á–Ω–æ—Å—Ç—å –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {new_acc:.3f}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ä–æ–π –º–æ–¥–µ–ª–∏
        old_acc = 0
        if os.path.exists(MODEL_PATH):
            try:
                old_model = joblib.load(MODEL_PATH)
                y_pred_old = old_model.predict(X_test)
                old_acc = accuracy_score(y_test, y_pred_old)
                logger.info(f"üìâ –¢–æ—á–Ω–æ—Å—Ç—å —Å—Ç–∞—Ä–æ–π –º–æ–¥–µ–ª–∏: {old_acc:.3f}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ä–æ–π –º–æ–¥–µ–ª–∏: {e}")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –æ–Ω–∞ –ª—É—á—à–µ
        if new_acc >= old_acc or not os.path.exists(MODEL_PATH):
            # –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä–æ–π –º–æ–¥–µ–ª–∏
            if os.path.exists(MODEL_PATH):
                try:
                    os.rename(MODEL_PATH, OLD_MODEL_PATH)
                    logger.info("üóÇÔ∏è –°—Ç–∞—Ä–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏
            os.makedirs("models", exist_ok=True)
            joblib.dump(new_model, MODEL_PATH)
            logger.info("‚úÖ –ù–æ–≤–∞—è AI-–º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
            
            # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
            logger.info("\n" + classification_report(y_test, y_pred))
            
        else:
            logger.warning("‚ùå –ù–æ–≤–∞—è –º–æ–¥–µ–ª—å —Ö—É–∂–µ —Å—Ç–∞—Ä–æ–π - –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç–∞—Ä—É—é")
        
        # –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        importances = new_model.feature_importances_
        logger.info("üìä –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        for name, score in zip(feature_names, importances):
            logger.info(f"  {name}: {score:.3f}")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        plt.figure(figsize=(12, 6))
        plt.bar(feature_names, importances, color='green', alpha=0.7)
        plt.title("üîç –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–æ–¥–µ–ª–∏")
        plt.xlabel("–ü—Ä–∏–∑–Ω–∞–∫–∏")
        plt.ylabel("–í–∞–∂–Ω–æ—Å—Ç—å")
        plt.xticks(rotation=45)
        plt.tight_layout()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
        os.makedirs("charts", exist_ok=True)
        plt.savefig("charts/feature_importance.png", dpi=300, bbox_inches='tight')
        plt.close()
        logger.info("üìä –ì—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")

def create_basic_model():
    """–°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ —Å –ø—Ä–∏–º–µ—Ä–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
    logger.info("üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")
    
    # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    data = {
        "rsi": [25, 70, 45, 80, 30, 65, 50, 40, 60, 35, 75, 28, 55, 85, 20],
        "macd": [0.5, -0.3, 0.1, -0.4, 0.6, -0.2, 0.0, 0.3, -0.1, 0.4, -0.5, 0.7, 0.2, -0.6, 0.8],
        "signal": ["BUY", "SELL", "HOLD", "SELL", "BUY", "SELL", "HOLD", "BUY", "SELL", "BUY", "SELL", "BUY", "HOLD", "SELL", "BUY"],
        "success": [1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1]
    }
    
    df = pd.DataFrame(data)
    df["signal_encoded"] = df["signal"].map({"BUY": 1, "SELL": -1, "HOLD": 0})
    df["pattern_score"] = np.random.uniform(0, 6, len(df))
    df["confidence"] = np.random.uniform(20, 90, len(df))
    
    X = df[["rsi", "macd", "signal_encoded", "pattern_score", "confidence"]]
    y = df["success"]
    
    # –û–±—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X, y)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    os.makedirs("models", exist_ok=True)
    joblib.dump(model, MODEL_PATH)
    logger.info("‚úÖ –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")

def retrain_model():
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ —Ç–µ–ª–µ–≥—Ä–∞–º –±–æ—Ç–∞)"""
    logger.info("üîÅ –ó–∞–ø—É—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏...")
    try:
        train_model()
        logger.info("‚úÖ –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {e}")
        raise e

def get_model_info():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏"""
    if not os.path.exists(MODEL_PATH):
        return "‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
    
    try:
        model = joblib.load(MODEL_PATH)
        
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        info = {
            "type": type(model).__name__,
            "n_estimators": getattr(model, 'n_estimators', 'N/A'),
            "max_depth": getattr(model, 'max_depth', 'N/A'),
            "n_features": getattr(model, 'n_features_in_', 'N/A')
        }
        
        return info
        
    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}"

if __name__ == "__main__":
    train_model()
