# analysis/technical_indicators.py - UNIFIED ATR + UNIFIED CACHE VERSION

from __future__ import annotations

import time
import logging
import hashlib
import numpy as np
import pandas as pd
from typing import List, Dict, Any, Optional, Tuple
from functools import lru_cache


_EPS = 1e-12

# ‚úÖ UNIFIED CACHE INTEGRATION
try:
    from utils.unified_cache import get_cache_manager, CacheNamespace
    cache_manager = get_cache_manager()
    CACHE_AVAILABLE = True
    logging.info("üìä Technical Indicators: Unified Cache Manager loaded")
except ImportError as e:
    logging.warning(f"üìä Technical Indicators: Unified Cache not available, using fallback: {e}")
    cache_manager = None
    CACHE_AVAILABLE = False

# =============================================================================
# UNIFIED ATR FUNCTIONS - –ó–ê–ú–ï–ù–Ø–ï–¢ –í–°–ï –î–£–ë–õ–ò–†–£–Æ–©–ò–ï–°–Ø ATR –í –ü–†–û–ï–ö–¢–ï
# =============================================================================

def get_unified_atr(df: pd.DataFrame, period: int = 14, method: str = 'ewm') -> Optional[float]:
    """
    ‚úÖ UNIFIED ATR FUNCTION - –ï–¥–∏–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ATR –¥–ª—è –≤—Å–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
    
    –ó–∞–º–µ–Ω—è–µ—Ç –≤—Å–µ –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è ATR —Ñ—É–Ω–∫—Ü–∏–∏ –≤:
    - main.py ‚Üí atr()
    - telegram/bot_handler.py ‚Üí _atr()
    - risk_manager.py ‚Üí _calculate_atr()
    - ml/adaptive_model.py ‚Üí –≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è ATR
    - analysis/market_analyzer.py ‚Üí –≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è ATR
    
    Args:
        df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ open, high, low, close, volume
        period: –ü–µ—Ä–∏–æ–¥ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ ATR (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 14)
        method: 'ewm' (Exponential Weighted) –∏–ª–∏ 'sma' (Simple Moving Average)
        
    Returns:
        float: ATR –∑–Ω–∞—á–µ–Ω–∏–µ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        
    Example:
        >>> df = pd.DataFrame({'high': [102, 103], 'low': [99, 100], 'close': [101, 102]})
        >>> atr_value = get_unified_atr(df, period=14, method='ewm')
        >>> print(f"ATR: {atr_value:.6f}")
    """
    
    if df is None or df.empty:
        logging.debug("üìä Unified ATR: empty DataFrame received")
        return None

    required_cols = {"high", "low", "close"}
    if not required_cols.issubset(df.columns):
        missing = required_cols - set(df.columns)
        logging.error(f"üìä Unified ATR: missing columns {missing}")
        return None

    try:
        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        high = pd.to_numeric(df["high"], errors="coerce").ffill()
        low = pd.to_numeric(df["low"], errors="coerce").ffill()
        close = pd.to_numeric(df["close"], errors="coerce").ffill()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        min_periods = min(5, max(1, period // 3))  # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –º–∏–Ω–∏–º—É–º
        if len(df) < min_periods:
            logging.debug(f"üìä Unified ATR: insufficient data {len(df)} < {min_periods}")
            # –§–æ–ª–±—ç–∫: –ø—Ä–æ—Å—Ç–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
            return float((high - low).mean()) if len(df) > 0 else None

        # True Range calculation (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        prev_close = close.shift(1)
        
        # Vectorized True Range calculation
        tr1 = (high - low).abs()
        tr2 = (high - prev_close).abs() 
        tr3 = (low - prev_close).abs()
        
        # Efficient max calculation
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        
        # Handle edge cases
        tr = tr.fillna(tr1)  # Fallback to high-low if prev_close issues
        
        # ATR calculation based on method
        if method.lower() == 'sma':
            # Simple Moving Average method (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å risk_manager.py)
            atr_series = tr.rolling(window=period, min_periods=min_periods).mean()
        else:
            # Exponential Weighted Moving Average (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
            alpha = 1.0 / period
            atr_series = tr.ewm(alpha=alpha, adjust=False, min_periods=min_periods).mean()
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        if atr_series.empty or atr_series.isna().all():
            logging.debug("üìä Unified ATR: no valid ATR values calculated")
            return None
            
        atr_value = atr_series.iloc[-1]
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if pd.isna(atr_value) or not np.isfinite(atr_value) or atr_value <= 0:
            logging.debug(f"üìä Unified ATR: invalid result {atr_value}")
            # –§–æ–ª–±—ç–∫ –∫ –ø—Ä–æ—Å—Ç–æ–º—É —Ä–∞—Å—á–µ—Ç—É
            return float(tr.mean()) if tr.notna().any() else None
            
        result = float(atr_value)
        logging.debug(f"üìä Unified ATR [{method}]: {result:.6f} (period={period}, data_len={len(df)})")
        
        return result

    except Exception as e:
        logging.error(f"üìä Unified ATR calculation failed: {e}")
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Ñ–æ–ª–±—ç–∫
        try:
            simple_range = (df["high"] - df["low"]).mean()
            return float(simple_range) if pd.notna(simple_range) else None
        except Exception:
            return None


def atr(df: pd.DataFrame, period: int = 14) -> Optional[float]:
    """
    ‚úÖ COMPATIBILITY ALIAS - –ê–ª–∏–∞—Å –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    
    –ó–∞–º–µ–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é atr() –≤ main.py
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç EWM –º–µ—Ç–æ–¥ –∫–∞–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç
    """
    return get_unified_atr(df, period, method='ewm')


def _atr_for_telegram(df: pd.DataFrame, period: int = 14) -> float:
    """
    ‚úÖ TELEGRAM COMPATIBILITY - –ó–∞–º–µ–Ω—è–µ—Ç _atr() –≤ bot_handler.py
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç float (–Ω–µ Optional) –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å Telegram –∫–æ–º–∞–Ω–¥–∞–º–∏
    """
    result = get_unified_atr(df, period, method='ewm')
    return float(result) if result is not None else 0.0


def _atr_for_risk_manager(df: pd.DataFrame, period: Optional[int] = None) -> float:
    """
    ‚úÖ RISK MANAGER COMPATIBILITY - –ó–∞–º–µ–Ω—è–µ—Ç _calculate_atr() –≤ risk_manager.py
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–∞–∫ EWM, —Ç–∞–∫ –∏ SMA –º–µ—Ç–æ–¥ —á–µ—Ä–µ–∑ env –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç EWM (–±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π)
    """
    import os
    
    # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –º–µ—Ç–æ–¥–∞ —á–µ—Ä–µ–∑ env
    atr_method = os.getenv("RISK_ATR_METHOD", "ewm").lower()  # ewm –∏–ª–∏ sma
    period = period or int(os.getenv("ATR_PERIOD", 14))
    
    result = get_unified_atr(df, period, method=atr_method)
    
    # Risk manager –æ–∂–∏–¥–∞–µ—Ç float, –Ω–µ None
    if result is None:
        # –§–æ–ª–±—ç–∫ –¥–ª—è risk manager
        try:
            return float(df["close"].iloc[-1] * 0.02)  # 2% –æ—Ç —Ü–µ–Ω—ã
        except Exception:
            return 100.0  # –ö—Ä–∞–π–Ω–∏–π —Ñ–æ–ª–±—ç–∫
            
    return float(result)


def _atr_series_for_ml(df: pd.DataFrame, period: int = 14) -> pd.Series:
    """
    ‚úÖ ML MODEL COMPATIBILITY - –î–ª—è ml/adaptive_model.py
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç Series –¥–ª—è –≤—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏—è –≤ ML feature engineering
    """
    try:
        if df is None or df.empty or len(df) < 2:
            return pd.Series([0.0] * len(df), index=df.index if not df.empty else [])

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –∞–ª–≥–æ—Ä–∏—Ç–º —á—Ç–æ –∏ –≤ get_unified_atr
        high = pd.to_numeric(df["high"], errors="coerce")
        low = pd.to_numeric(df["low"], errors="coerce") 
        close = pd.to_numeric(df["close"], errors="coerce")
        
        prev_close = close.shift(1)
        tr1 = (high - low).abs()
        tr2 = (high - prev_close).abs()
        tr3 = (low - prev_close).abs()
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        
        # EWM –¥–ª—è ML (–±–æ–ª–µ–µ –≥–ª–∞–¥–∫–∏–µ features)
        alpha = 1.0 / period
        atr_series = tr.ewm(alpha=alpha, adjust=False, min_periods=1).mean()
        
        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ó–∞–º–µ–Ω—è–µ–º deprecated fillna(method='bfill')
        atr_series = atr_series.bfill().fillna(0.0)
        
        return atr_series.astype('float64')
        
    except Exception as e:
        logging.error(f"üìä ATR series for ML failed: {e}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–µ–≤–æ–π series —Ç–æ–π –∂–µ –¥–ª–∏–Ω—ã
        return pd.Series([0.0] * len(df), index=df.index)

# =============================================================================
# ‚úÖ UNIFIED CACHE FUNCTIONS - –ó–ê–ú–ï–ù–ê –°–¢–ê–†–û–ì–û –ö–≠–®–ê
# =============================================================================

def _create_cache_key(df: pd.DataFrame, params: str = "") -> str:
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–ª—é—á–∞ –∫—ç—à–∞ –¥–ª—è DataFrame"""
    try:
        if df.empty:
            return f"empty_{params}"
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å—Ç—Ä–æ–∫ + —Ä–∞–∑–º–µ—Ä + params –¥–ª—è –∫–ª—é—á–∞
        tail_data = df.tail(10)[['close', 'volume', 'high', 'low']].values
        data_str = f"{len(df)}_{str(tail_data)}_{params}"
        return hashlib.md5(data_str.encode()).hexdigest()[:16]
    except Exception:
        return f"fallback_{len(df)}_{time.time()}_{params}"

def _get_cached_indicators(df: pd.DataFrame, use_cache: bool = True) -> Optional[pd.DataFrame]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –∏–∑ unified –∫—ç—à–∞"""
    if not use_cache or not CACHE_AVAILABLE:
        return None
    
    try:
        cache_key = _create_cache_key(df, "indicators")
        cached_result = cache_manager.get(cache_key, CacheNamespace.INDICATORS)
        
        if cached_result is not None:
            logging.debug(f"üìä Cache HIT for indicators: {cache_key[:8]}...")
            return cached_result
        else:
            logging.debug(f"üìä Cache MISS for indicators: {cache_key[:8]}...")
            return None
            
    except Exception as e:
        logging.error(f"üìä Cache get failed: {e}")
        return None

def _set_cached_indicators(df: pd.DataFrame, result: pd.DataFrame, use_cache: bool = True) -> bool:
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –≤ unified –∫—ç—à"""
    if not use_cache or not CACHE_AVAILABLE:
        return False
    
    try:
        cache_key = _create_cache_key(df, "indicators")
        success = cache_manager.set(
            cache_key, 
            result.copy(), 
            CacheNamespace.INDICATORS,
            metadata={"rows": len(result), "cols": len(result.columns)}
        )
        
        if success:
            logging.debug(f"üìä Cache SET for indicators: {cache_key[:8]}...")
        
        return success
        
    except Exception as e:
        logging.error(f"üìä Cache set failed: {e}")
        return False

# =============================================================================
# –ë–ê–ó–û–í–´–ï –§–£–ù–ö–¶–ò–ò –ò–ù–î–ò–ö–ê–¢–û–†–û–í (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# =============================================================================

def _safe_tail_fill(s: pd.Series) -> pd.Series:
    """–ó–∞–ø–æ–ª–Ω—è–µ—Ç —Ç–æ–ª—å–∫–æ –•–í–û–°–¢–û–í–´–ï NaN –ø–æ—Å–ª–µ–¥–Ω–∏–º –≤–∞–ª–∏–¥–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º"""
    if s is None or s.empty or not s.notna().any():
        return s
    last_valid = s.last_valid_index()
    if last_valid is None:
        return s
    pos = s.index.get_loc(last_valid)
    if isinstance(pos, slice):
        pos = pos.stop - 1
    start = pos + 1
    if start < len(s):
        s = s.copy()
        s.iloc[start:] = s.iloc[start:].fillna(s.iloc[pos])
    return s

def _to_f64(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s, errors="coerce").astype("float64")

# =============================================================================
# –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –†–ê–°–ß–ï–¢–´ –° –ü–û–í–¢–û–†–ù–´–ú –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï–ú
# =============================================================================

class IndicatorCalculator:
    """–ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏"""
    
    def __init__(self):
        self._ema_cache = {}  # –õ–æ–∫–∞–ª—å–Ω—ã–π –∫—ç—à –¥–ª—è EMA —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤
        
    def calculate_emas(self, close: pd.Series, periods: list) -> Dict[int, pd.Series]:
        """–†–∞—Å—á–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö EMA –∑–∞ –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥"""
        result = {}
        for period in periods:
            cache_key = f"ema_{period}_{len(close)}"
            if cache_key in self._ema_cache:
                result[period] = self._ema_cache[cache_key]
            else:
                ema = close.ewm(span=period, adjust=False, min_periods=1).mean()
                self._ema_cache[cache_key] = ema
                result[period] = ema
        return result
    
    def calculate_rsi(self, close: pd.Series, period: int = 14) -> pd.Series:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π RSI"""
        delta = close.diff()
        gain = delta.clip(lower=0.0)
        loss = -delta.clip(upper=0.0)
        roll_up = gain.ewm(alpha=1 / period, adjust=False, min_periods=1).mean()
        roll_down = loss.ewm(alpha=1 / period, adjust=False, min_periods=1).mean()
        rs = roll_up / (roll_down + _EPS)
        rsi = 100.0 - (100.0 / (1.0 + rs))
        return rsi.astype("float64")
    
    def calculate_macd(self, close: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π MACD"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–µ EMA
        emas = self.calculate_emas(close, [fast, slow])
        macd = (emas[fast] - emas[slow]).astype("float64")
        macd_signal = macd.ewm(span=signal, adjust=False, min_periods=1).mean().astype("float64")
        macd_hist = (macd - macd_signal).astype("float64")
        return macd, macd_signal, macd_hist
    
    def calculate_bollinger(self, close: pd.Series, period: int = 20, num_std: float = 2.0):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª–æ—Å—ã –ë–æ–ª–ª–∏–Ω–¥–∂–µ—Ä–∞"""
        # SMA —É–∂–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–∞
        sma = close.rolling(window=period, min_periods=1).mean()
        std = close.rolling(window=period, min_periods=1).std(ddof=0).fillna(0.0)
        upper = sma + num_std * std
        lower = sma - num_std * std
        
        # –ü–æ–∑–∏—Ü–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
        rng = (upper - lower)
        bb_position = ((close - lower) / (rng + _EPS)).clip(0.0, 1.0).astype("float64")
        
        return sma.astype("float64"), upper.astype("float64"), lower.astype("float64"), bb_position
    
    def clear_cache(self):
        """–û—á–∏—Å—Ç–∏—Ç—å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –∫—ç—à"""
        self._ema_cache.clear()

# =============================================================================
# ‚úÖ –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –° UNIFIED CACHE –ò UNIFIED ATR
# =============================================================================

def calculate_all_indicators(df: pd.DataFrame, use_cache: bool = True) -> pd.DataFrame:
    """
    ‚úÖ UNIFIED VERSION: –†–∞—Å—á—ë—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å UNIFIED CACHE –∏ UNIFIED ATR
    
    –¢–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç:
    - Unified Cache Manager –≤–º–µ—Å—Ç–æ _indicator_cache
    - get_unified_atr() –≤–º–µ—Å—Ç–æ –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ ATR —Ä–∞—Å—á–µ—Ç–∞
    - Namespace INDICATORS –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
    
    Features:
    - –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ UnifiedCacheManager
    - –ï–î–ò–ù–´–ô ATR —Ä–∞—Å—á–µ—Ç —á–µ—Ä–µ–∑ get_unified_atr()
    - –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
    - –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã
    - Graceful –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
    
    Args:
        df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ open, high, low, close, volume
        use_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å unified –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True)
        
    Returns:
        DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏
    """
    start_time = time.time()
    
    if df is None or df.empty:
        logging.debug("üìä Technical indicators: empty DataFrame received")
        return pd.DataFrame()

    required = {"open", "high", "low", "close", "volume"}
    if not required.issubset(df.columns):
        missing = required - set(df.columns)
        logging.error(f"üìä Missing required columns: {missing}")
        return df.copy() if isinstance(df, pd.DataFrame) else pd.DataFrame()

    # ‚úÖ –ü–†–û–í–ï–†–Ø–ï–ú UNIFIED CACHE
    cached_result = _get_cached_indicators(df, use_cache)
    if cached_result is not None:
        calc_time = time.time() - start_time
        logging.debug(f"üìä Indicators from UNIFIED cache in {calc_time:.3f}s")
        return cached_result

    logging.debug(f"üìä Calculating indicators for {len(df)} rows")

    try:
        out = df.copy()
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –∫ datetime
        if not isinstance(out.index, pd.DatetimeIndex):
            try:
                out.index = pd.to_datetime(out.index, utc=True, errors='coerce')
            except Exception as e:
                logging.debug(f"üìä Could not convert index to datetime: {e}")

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        try:
            out = out.sort_index()
        except Exception:
            pass

        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤
        for c in ("open", "high", "low", "close", "volume"):
            out[c] = _to_f64(out[c])

        close = out["close"]
        high = out["high"] 
        low = out["low"]
        volume = out["volume"]

        # –°–æ–∑–¥–∞–µ–º –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        calc = IndicatorCalculator()

        # RSI
        out["rsi"] = _safe_tail_fill(calc.calculate_rsi(close, 14))

        # MACD + EMAs (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ)
        macd, macd_sig, macd_hist = calc.calculate_macd(close, 12, 26, 9)
        out["macd"] = _safe_tail_fill(macd)
        out["macd_signal"] = _safe_tail_fill(macd_sig)
        out["macd_hist"] = _safe_tail_fill(macd_hist)

        # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ EMA –∑–∞ –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥
        ema_periods = [12, 20, 26, 50, 200]
        emas = calc.calculate_emas(close, ema_periods)
        
        for period in ema_periods:
            out[f"ema_{period}"] = _safe_tail_fill(emas[period])
        
        # –ê–ª–∏–∞—Å—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        out["ema_fast"] = out["ema_12"]
        out["ema_slow"] = out["ema_26"]

        # SMA (—Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ)
        out["sma_50"] = _safe_tail_fill(close.rolling(50, min_periods=1).mean().astype("float64"))
        out["sma_200"] = _safe_tail_fill(close.rolling(200, min_periods=1).mean().astype("float64"))

        # Stochastic
        lowest_low = low.rolling(window=14, min_periods=1).min()
        highest_high = high.rolling(window=14, min_periods=1).max()
        rng = (highest_high - lowest_low)
        stoch_k = ((close - lowest_low) / (rng.replace(0, np.nan) + _EPS) * 100.0).clip(0.0, 100.0)
        stoch_d = stoch_k.rolling(window=3, min_periods=1).mean()
        
        out["stoch_k"] = _safe_tail_fill(stoch_k.astype("float64"))
        out["stoch_d"] = _safe_tail_fill(stoch_d.astype("float64"))

        # ‚úÖ UNIFIED ATR - —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–¥–∏–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
        unified_atr_series = _atr_series_for_ml(out, period=14)
        out["atr"] = _safe_tail_fill(unified_atr_series)

        # ADX (–∏—Å–ø–æ–ª—å–∑—É—è UNIFIED ATR)
        up_move = high.diff()
        down_move = -low.diff()
        plus_dm = pd.Series(np.where((up_move > down_move) & (up_move > 0), up_move, 0.0), index=high.index)
        minus_dm = pd.Series(np.where((down_move > up_move) & (down_move > 0), down_move, 0.0), index=high.index)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–π UNIFIED ATR
        atr = out["atr"]
        plus_di = 100.0 * (plus_dm.ewm(alpha=1 / 14, adjust=False, min_periods=1).mean() / (atr + _EPS))
        minus_di = 100.0 * (minus_dm.ewm(alpha=1 / 14, adjust=False, min_periods=1).mean() / (atr + _EPS))
        dx = (100.0 * (plus_di - minus_di).abs() / (plus_di + minus_di + _EPS)).astype("float64")
        adx = dx.ewm(alpha=1 / 14, adjust=False, min_periods=1).mean()
        
        out["adx"] = _safe_tail_fill(adx.astype("float64"))

        # Bollinger Bands (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
        bb_mid, bb_upper, bb_lower, bb_position = calc.calculate_bollinger(close, 20, 2.0)
        out["bb_mid"] = _safe_tail_fill(bb_mid)
        out["bb_upper"] = _safe_tail_fill(bb_upper)
        out["bb_lower"] = _safe_tail_fill(bb_lower)
        out["bb_position"] = _safe_tail_fill(bb_position)

        # Volume ratio
        v_sma = volume.rolling(window=20, min_periods=1).mean()
        volume_ratio = (volume / (v_sma + _EPS)).astype("float64")
        out["volume_ratio"] = _safe_tail_fill(volume_ratio)

        # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º float64 –¥–ª—è –≤—Å–µ—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        indicator_cols = [col for col in out.columns if col not in df.columns]
        for col in indicator_cols:
            out[col] = _to_f64(out[col])

        # –û—á–∏—â–∞–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –∫—ç—à –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞
        calc.clear_cache()

        # ‚úÖ –°–û–•–†–ê–ù–Ø–ï–ú –í UNIFIED CACHE
        _set_cached_indicators(df, out, use_cache)

        calc_time = time.time() - start_time
        cache_status = "UNIFIED cached" if use_cache and CACHE_AVAILABLE else "not cached"
        logging.debug(f"üìä Indicators calculated in {calc_time:.3f}s, {cache_status}")
        
        return out

    except Exception as e:
        logging.exception(f"Technical indicators calculation failed: {e}")
        return df.copy()

# =============================================================================
# ‚úÖ UNIFIED CACHE UTILITIES
# =============================================================================

def clear_indicator_cache():
    """‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –û—á–∏—Å—Ç–∏—Ç—å unified –∫—ç—à –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
    if CACHE_AVAILABLE:
        cache_manager.clear_namespace(CacheNamespace.INDICATORS)
        logging.info("üìä Unified indicator cache cleared")
    else:
        logging.warning("üìä Unified cache not available")

def get_cache_stats() -> Dict[str, Any]:
    """‚úÖ –û–ë–ù–û–í–õ–ï–ù–û: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ unified –∫—ç—à–∞"""
    if CACHE_AVAILABLE:
        all_stats = cache_manager.get_stats()
        return {
            "indicators_namespace": all_stats["namespaces"].get("indicators", {}),
            "global_stats": all_stats["global"],
            "unified_cache": True
        }
    else:
        return {
            "unified_cache": False,
            "message": "Unified cache not available"
        }

def get_indicator_cache_top_keys(limit: int = 10) -> List[Dict[str, Any]]:
    """‚úÖ –ù–û–í–û–ï: –¢–æ–ø –∫–ª—é—á–µ–π –∫—ç—à–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
    if CACHE_AVAILABLE:
        return cache_manager.get_top_keys(CacheNamespace.INDICATORS, limit)
    else:
        return []

# =============================================================================
# –ë–´–°–¢–†–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø –û–¢–î–ï–õ–¨–ù–´–• –ò–ù–î–ò–ö–ê–¢–û–†–û–í
# =============================================================================

@lru_cache(maxsize=128)
def quick_rsi(close_hash: str, period: int = 14) -> float:
    """–ë—ã—Å—Ç—Ä—ã–π RSI –¥–ª—è –æ–¥–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è (—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º)"""
    # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å —Ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    # –í —Ä–µ–∞–ª—å–Ω–æ–º –∫–æ–¥–µ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥—Ä—É–≥–∏–º —Å–ø–æ—Å–æ–±–æ–º
    pass

def get_last_indicator_value(df: pd.DataFrame, indicator: str) -> Optional[float]:
    """–ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞"""
    try:
        indicators = calculate_all_indicators(df, use_cache=True)
        if indicator in indicators.columns:
            value = indicators[indicator].iloc[-1]
            return float(value) if pd.notna(value) else None
    except Exception as e:
        logging.error(f"Failed to get {indicator}: {e}")
    return None

# =============================================================================
# UNIFIED ATR TESTING UTILITIES
# =============================================================================

def test_unified_atr_compatibility():
    """
    ‚úÖ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ unified ATR
    """
    try:
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_data = pd.DataFrame({
            'open': [100, 101, 102, 103, 104],
            'high': [102, 103, 104, 105, 106], 
            'low': [99, 100, 101, 102, 103],
            'close': [101, 102, 103, 104, 105],
            'volume': [1000, 1100, 1200, 1300, 1400]
        })
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—Å–µ unified —Ñ—É–Ω–∫—Ü–∏–∏
        results = {}
        
        # –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
        results['unified'] = get_unified_atr(test_data, period=3, method='ewm')
        results['unified_sma'] = get_unified_atr(test_data, period=3, method='sma')
        
        # –ê–ª–∏–∞—Å—ã —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        results['main_atr'] = atr(test_data, period=3)
        results['telegram_atr'] = _atr_for_telegram(test_data, period=3)
        results['risk_atr'] = _atr_for_risk_manager(test_data, period=3)
        results['ml_atr'] = _atr_series_for_ml(test_data, period=3).iloc[-1]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç —Ä–∞–∑—É–º–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        for name, value in results.items():
            print(f"üìä {name}: {value}")
            assert value is not None and value > 0, f"{name} returned invalid value: {value}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ EWM –≤–µ—Ä—Å–∏–∏ –¥–∞—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        ewm_functions = ['unified', 'main_atr', 'telegram_atr']
        ewm_values = [results[func] for func in ewm_functions]
        
        # –î–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–±–æ–ª—å—à–∏–µ —Ä–∞–∑–ª–∏—á–∏—è –∏–∑-–∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
        assert all(abs(v - ewm_values[0]) < 0.01 for v in ewm_values), \
            f"EWM functions give different results: {ewm_values}"
        
        print("‚úÖ All unified ATR functions work correctly!")
        return True
        
    except Exception as e:
        print(f"‚ùå Unified ATR test failed: {e}")
        return False

def test_unified_cache_integration():
    """‚úÖ –ù–û–í–û–ï: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ unified cache"""
    if not CACHE_AVAILABLE:
        print("‚ùå Unified cache not available for testing")
        return False
    
    try:
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_data = pd.DataFrame({
            'open': [100, 101, 102],
            'high': [102, 103, 104], 
            'low': [99, 100, 101],
            'close': [101, 102, 103],
            'volume': [1000, 1100, 1200]
        })
        
        # –û—á–∏—â–∞–µ–º –∫—ç—à
        clear_indicator_cache()
        
        # –ü–µ—Ä–≤—ã–π –≤—ã–∑–æ–≤ - –¥–æ–ª–∂–µ–Ω –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å—Å—è
        start_time = time.time()
        result1 = calculate_all_indicators(test_data, use_cache=True)
        time1 = time.time() - start_time
        
        # –í—Ç–æ—Ä–æ–π –≤—ã–∑–æ–≤ - –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–∑ –∫—ç—à–∞
        start_time = time.time()
        result2 = calculate_all_indicators(test_data, use_cache=True)
        time2 = time.time() - start_time
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        assert result1.equals(result2), "Cached result differs from original"
        assert time2 < time1 * 0.5, f"Cache didn't speed up calculation: {time1:.3f}s vs {time2:.3f}s"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = get_cache_stats()
        assert stats["unified_cache"], "Unified cache should be available"
        assert stats["indicators_namespace"]["entries"] > 0, "Cache should have entries"
        
        print("‚úÖ Unified cache integration works correctly!")
        print(f"üìä Performance: {time1:.3f}s -> {time2:.3f}s ({time2/time1*100:.1f}%)")
        return True
        
    except Exception as e:
        print(f"‚ùå Unified cache test failed: {e}")
        return False

# –≠–∫—Å–ø–æ—Ä—Ç –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
__all__ = [
    # ‚úÖ –ù–û–í–´–ï UNIFIED –§–£–ù–ö–¶–ò–ò
    'get_unified_atr',           # –ì–ª–∞–≤–Ω–∞—è unified —Ñ—É–Ω–∫—Ü–∏—è
    'atr',                       # –ê–ª–∏–∞—Å –¥–ª—è main.py
    '_atr_for_telegram',         # –ê–ª–∏–∞—Å –¥–ª—è bot_handler.py  
    '_atr_for_risk_manager',     # –ê–ª–∏–∞—Å –¥–ª—è risk_manager.py
    '_atr_series_for_ml',        # –î–ª—è ML –º–æ–¥–µ–ª–∏
    
    # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ (–æ–±–Ω–æ–≤–ª–µ–Ω—ã –¥–ª—è unified cache)
    'calculate_all_indicators',
    'clear_indicator_cache', 
    'get_cache_stats',
    'get_last_indicator_value',
    
    # ‚úÖ –ù–û–í–´–ï UNIFIED CACHE –§–£–ù–ö–¶–ò–ò
    'get_indicator_cache_top_keys',
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    'test_unified_atr_compatibility',
    'test_unified_cache_integration'
]